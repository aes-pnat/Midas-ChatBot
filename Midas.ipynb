{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "import pandas as pd\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#FinanceInc/finbert-pretrain\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"FinanceInc/finbert-pretrain\", from_pt=True)\n",
    "finbert_model = TFAutoModel.from_pretrained(\"FinanceInc/finbert-pretrain\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109751808 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,751,808\n",
      "Trainable params: 109,751,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finbert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user report                            total submissions   10   first seen in wsb   2 years ago   total comments   332   previous best dd      account age   3 years   scan  comment     submission   \n"
     ]
    }
   ],
   "source": [
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    # tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words and lemmatize the words\n",
    "    # tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    return text\n",
    "\n",
    "input_text = '\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**Total Submissions**|10|**First Seen In WSB**|2 years ago\\n**Total Comments**|332|**Previous Best DD**|\\n**Account Age**|3 years|[^scan ^comment ](https://www.reddit.com/message/compose/?to=VisualMod&subject=scan_comment&message=Replace%20this%20text%20with%20a%20comment%20ID%20(which%20looks%20like%20h26cq3k\\\\)%20to%20have%20the%20bot%20scan%20your%20comment%20and%20correct%20your%20first%20seen%20date.)|[^scan ^submission ](https://www.reddit.com/message/compose/?to=VisualMod&subject=scan_submission&message=Replace%20this%20text%20with%20a%20submission%20ID%20(which%20looks%20like%20h26cq3k\\\\)%20to%20have%20the%20bot%20scan%20your%20submission%20and%20correct%20your%20first%20seen%20date.)'\n",
    "preprocessed_text = preprocess_text(input_text)\n",
    "print(preprocessed_text)\n",
    "\n",
    "def decontractions(phrase):\n",
    "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
    "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "\n",
    "\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trader who made money with tight stoploss ther...</td>\n",
       "      <td>cut losses early  take profits always simple c...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaked email from microsoft ceo says salaried ...</td>\n",
       "      <td>we have exceeded all profit expectations  tha...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>does anyone know where sbf is now</td>\n",
       "      <td>i ve worked with a few people that have gotten...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>december buys cvna  182k to  2 500 000</td>\n",
       "      <td>user report                            tota...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dumbest reason in the world to buy a stoc...</td>\n",
       "      <td>i don t think those quotes are that conflictin...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41008</th>\n",
       "      <td>next week on stock market</td>\n",
       "      <td>it seems to be mimicking my total account value</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41009</th>\n",
       "      <td>whatcha doin  here  huh</td>\n",
       "      <td>this is funny  the guy with glass actually got...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41010</th>\n",
       "      <td>commerzbank ag down 12   credit suisse group a...</td>\n",
       "      <td>my portfolio is up 1 08  today  so far   also ...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41011</th>\n",
       "      <td>coca cola   ko  vs pepsi   pep   are either wo...</td>\n",
       "      <td>izbrisano</td>\n",
       "      <td>dividends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41012</th>\n",
       "      <td>meta  the hottest stock in tech  is up 140  si...</td>\n",
       "      <td>i almost bought that shit at the low god dammit</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41013 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               questions  \\\n",
       "0      trader who made money with tight stoploss ther...   \n",
       "1      leaked email from microsoft ceo says salaried ...   \n",
       "2                    does anyone know where sbf is now     \n",
       "3                december buys cvna  182k to  2 500 000    \n",
       "4       the dumbest reason in the world to buy a stoc...   \n",
       "...                                                  ...   \n",
       "41008                         next week on stock market    \n",
       "41009                          whatcha doin  here  huh     \n",
       "41010  commerzbank ag down 12   credit suisse group a...   \n",
       "41011  coca cola   ko  vs pepsi   pep   are either wo...   \n",
       "41012  meta  the hottest stock in tech  is up 140  si...   \n",
       "\n",
       "                                                 answers            tags  \n",
       "0      cut losses early  take profits always simple c...     stockmarket  \n",
       "1       we have exceeded all profit expectations  tha...     stockmarket  \n",
       "2      i ve worked with a few people that have gotten...  wallstreetbets  \n",
       "3         user report                            tota...  wallstreetbets  \n",
       "4      i don t think those quotes are that conflictin...     stockmarket  \n",
       "...                                                  ...             ...  \n",
       "41008    it seems to be mimicking my total account value  wallstreetbets  \n",
       "41009  this is funny  the guy with glass actually got...     stockmarket  \n",
       "41010  my portfolio is up 1 08  today  so far   also ...     stockmarket  \n",
       "41011                                         izbrisano        dividends  \n",
       "41012    i almost bought that shit at the low god dammit          stocks  \n",
       "\n",
       "[41013 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_df_reddit = pd.read_csv('qna_df_reddit.csv')\n",
    "qna_df_reddit = qna_df_reddit.sample(frac=1).reset_index(drop=True)\n",
    "qna_df_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_df_reddit = qna_df_reddit.map(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trader who made money with tight stoploss ther...</td>\n",
       "      <td>cut losses early  take profits always simple c...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaked email from microsoft ceo says salaried ...</td>\n",
       "      <td>we have exceeded all profit expectations  tha...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>does anyone know where sbf is now</td>\n",
       "      <td>i ve worked with a few people that have gotten...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>december buys cvna  182k to  2 500 000</td>\n",
       "      <td>user report                            tota...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dumbest reason in the world to buy a stoc...</td>\n",
       "      <td>i don t think those quotes are that conflictin...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40801</th>\n",
       "      <td>next week on stock market</td>\n",
       "      <td>it seems to be mimicking my total account value</td>\n",
       "      <td>wallstreetbets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40802</th>\n",
       "      <td>whatcha doin  here  huh</td>\n",
       "      <td>this is funny  the guy with glass actually got...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40803</th>\n",
       "      <td>commerzbank ag down 12   credit suisse group a...</td>\n",
       "      <td>my portfolio is up 1 08  today  so far   also ...</td>\n",
       "      <td>stockmarket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40804</th>\n",
       "      <td>coca cola   ko  vs pepsi   pep   are either wo...</td>\n",
       "      <td>izbrisano</td>\n",
       "      <td>dividends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40805</th>\n",
       "      <td>meta  the hottest stock in tech  is up 140  si...</td>\n",
       "      <td>i almost bought that shit at the low god dammit</td>\n",
       "      <td>stocks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40806 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               questions  \\\n",
       "0      trader who made money with tight stoploss ther...   \n",
       "1      leaked email from microsoft ceo says salaried ...   \n",
       "2                    does anyone know where sbf is now     \n",
       "3                december buys cvna  182k to  2 500 000    \n",
       "4       the dumbest reason in the world to buy a stoc...   \n",
       "...                                                  ...   \n",
       "40801                         next week on stock market    \n",
       "40802                          whatcha doin  here  huh     \n",
       "40803  commerzbank ag down 12   credit suisse group a...   \n",
       "40804  coca cola   ko  vs pepsi   pep   are either wo...   \n",
       "40805  meta  the hottest stock in tech  is up 140  si...   \n",
       "\n",
       "                                                 answers            tags  \n",
       "0      cut losses early  take profits always simple c...     stockmarket  \n",
       "1       we have exceeded all profit expectations  tha...     stockmarket  \n",
       "2      i ve worked with a few people that have gotten...  wallstreetbets  \n",
       "3         user report                            tota...  wallstreetbets  \n",
       "4      i don t think those quotes are that conflictin...     stockmarket  \n",
       "...                                                  ...             ...  \n",
       "40801    it seems to be mimicking my total account value  wallstreetbets  \n",
       "40802  this is funny  the guy with glass actually got...     stockmarket  \n",
       "40803  my portfolio is up 1 08  today  so far   also ...     stockmarket  \n",
       "40804                                         izbrisano        dividends  \n",
       "40805    i almost bought that shit at the low god dammit          stocks  \n",
       "\n",
       "[40806 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_df_reddit['questions'] = qna_df_reddit['questions'].apply(lambda x: np.nan if re.match(r'^\\s*$', x) else x)\n",
    "qna_df_reddit['answers'] = qna_df_reddit['answers'].apply(lambda x: np.nan if re.match(r'^\\s*$', x) else x)\n",
    "\n",
    "qna_df_reddit = qna_df_reddit.dropna().reset_index(drop=True)\n",
    "qna_df_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_df_reddit['questions'] = qna_df_reddit['questions'].apply(lambda x: preprocess_text(x))\n",
    "qna_df_reddit['answers'] = qna_df_reddit['answers'].apply(lambda x: preprocess_text(x))\n",
    "\n",
    "qna_df_reddit['questions'] = qna_df_reddit['questions'].apply(lambda x: decontractions(x))\n",
    "qna_df_reddit['answers'] = qna_df_reddit['answers'].apply(lambda x: decontractions(x))\n",
    "\n",
    "qna_df_reddit['question_tokens'] = qna_df_reddit['questions'].apply(lambda x: finbert_tokenizer.tokenize(x))\n",
    "qna_df_reddit['answer_tokens'] = qna_df_reddit['answers'].apply(lambda x: finbert_tokenizer.tokenize(x))\n",
    "\n",
    "qna_df_reddit['question_tokens'] = qna_df_reddit['question_tokens'].apply(lambda x: ['[CLS]'] + x + ['[SEP]'])\n",
    "qna_df_reddit['answer_tokens'] = qna_df_reddit['answer_tokens'].apply(lambda x: ['[CLS]'] + x + ['[SEP]'])\n",
    "\n",
    "qna_df_reddit['question_ids'] = qna_df_reddit['question_tokens'].apply(lambda x: finbert_tokenizer.convert_tokens_to_ids(x))\n",
    "qna_df_reddit['answer_ids'] = qna_df_reddit['answer_tokens'].apply(lambda x: finbert_tokenizer.convert_tokens_to_ids(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>tags</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>answer_tokens</th>\n",
       "      <th>question_ids</th>\n",
       "      <th>answer_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trader who made money with tight stoploss ther...</td>\n",
       "      <td>cut losses early  take profits always simple c...</td>\n",
       "      <td>stockmarket</td>\n",
       "      <td>[[CLS], trade, ##r, who, made, money, with, ti...</td>\n",
       "      <td>[[CLS], cut, losses, early, take, profits, alw...</td>\n",
       "      <td>[3, 582, 437, 412, 295, 1247, 20, 4763, 4001, ...</td>\n",
       "      <td>[3, 2726, 274, 634, 362, 1458, 1433, 4665, 499...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leaked email from microsoft ceo says salaried ...</td>\n",
       "      <td>we have exceeded all profit expectations  tha...</td>\n",
       "      <td>stockmarket</td>\n",
       "      <td>[[CLS], leak, ##ed, email, from, microsoft, ce...</td>\n",
       "      <td>[[CLS], we, have, exceeded, all, profit, expec...</td>\n",
       "      <td>[3, 12641, 268, 4679, 23, 3466, 2303, 8276, 19...</td>\n",
       "      <td>[3, 13, 29, 2365, 69, 358, 746, 15, 304, 960, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>does anyone know where sbf is now</td>\n",
       "      <td>i ve worked with a few people that have gotten...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[[CLS], does, anyone, know, where, sb, ##f, is...</td>\n",
       "      <td>[[CLS], i, ve, worked, with, a, few, people, t...</td>\n",
       "      <td>[3, 262, 7355, 695, 214, 7775, 1423, 17, 212, 4]</td>\n",
       "      <td>[3, 44, 829, 4080, 20, 11, 806, 1043, 15, 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>december buys cvna  182k to  2 500 000</td>\n",
       "      <td>user report                            tota...</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[[CLS], december, buys, cv, ##na, 182, ##k, to...</td>\n",
       "      <td>[[CLS], user, report, total, submissions, 6, f...</td>\n",
       "      <td>[3, 109, 7233, 7314, 2886, 17104, 994, 9, 513,...</td>\n",
       "      <td>[3, 2502, 125, 87, 13777, 1146, 78, 921, 10, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the dumbest reason in the world to buy a stoc...</td>\n",
       "      <td>i don t think those quotes are that conflictin...</td>\n",
       "      <td>stockmarket</td>\n",
       "      <td>[[CLS], the, dum, ##bes, ##t, reason, in, the,...</td>\n",
       "      <td>[[CLS], i, don, t, think, those, quotes, are, ...</td>\n",
       "      <td>[3, 6, 18997, 25137, 463, 2040, 10, 6, 907, 9,...</td>\n",
       "      <td>[3, 44, 4950, 599, 135, 151, 12244, 21, 15, 24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40801</th>\n",
       "      <td>next week on stock market</td>\n",
       "      <td>it seems to be mimicking my total account value</td>\n",
       "      <td>wallstreetbets</td>\n",
       "      <td>[[CLS], next, week, on, stock, market, [SEP]]</td>\n",
       "      <td>[[CLS], it, seems, to, be, mimi, ##cki, ##ng, ...</td>\n",
       "      <td>[3, 165, 1952, 19, 93, 52, 4]</td>\n",
       "      <td>[3, 41, 1998, 9, 25, 27272, 26497, 1071, 657, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40802</th>\n",
       "      <td>whatcha doin  here  huh</td>\n",
       "      <td>this is funny  the guy with glass actually got...</td>\n",
       "      <td>stockmarket</td>\n",
       "      <td>[[CLS], what, ##cha, do, ##in, here, hu, ##h, ...</td>\n",
       "      <td>[[CLS], this, is, fun, ##ny, the, guy, with, g...</td>\n",
       "      <td>[3, 163, 9118, 123, 1419, 1094, 10374, 1078, 4]</td>\n",
       "      <td>[3, 26, 17, 15782, 5233, 6, 10037, 20, 4639, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40803</th>\n",
       "      <td>commerzbank ag down 12   credit suisse group a...</td>\n",
       "      <td>my portfolio is up 1 08  today  so far   also ...</td>\n",
       "      <td>stockmarket</td>\n",
       "      <td>[[CLS], commer, ##zb, ##ank, ag, down, 12, cre...</td>\n",
       "      <td>[[CLS], my, portfolio, is, up, 1, 08, today, s...</td>\n",
       "      <td>[3, 27903, 21596, 8515, 2708, 269, 315, 97, 11...</td>\n",
       "      <td>[3, 657, 318, 17, 129, 428, 7694, 1163, 96, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40804</th>\n",
       "      <td>coca cola   ko  vs pepsi   pep   are either wo...</td>\n",
       "      <td>izbrisano</td>\n",
       "      <td>dividends</td>\n",
       "      <td>[[CLS], coc, ##a, cola, ko, vs, pepsi, pep, ar...</td>\n",
       "      <td>[[CLS], i, ##zb, ##ris, ##ano, [SEP]]</td>\n",
       "      <td>[3, 16632, 363, 25424, 5338, 4364, 10987, 1327...</td>\n",
       "      <td>[3, 44, 21596, 6632, 10225, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40805</th>\n",
       "      <td>meta  the hottest stock in tech  is up 140  si...</td>\n",
       "      <td>i almost bought that shit at the low god dammit</td>\n",
       "      <td>stocks</td>\n",
       "      <td>[[CLS], meta, the, hot, ##test, stock, in, tec...</td>\n",
       "      <td>[[CLS], i, almost, bought, that, shi, ##t, at,...</td>\n",
       "      <td>[3, 12245, 6, 4387, 13850, 93, 10, 4579, 17, 1...</td>\n",
       "      <td>[3, 44, 1628, 4774, 15, 11125, 463, 28, 6, 536...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40806 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               questions  \\\n",
       "0      trader who made money with tight stoploss ther...   \n",
       "1      leaked email from microsoft ceo says salaried ...   \n",
       "2                    does anyone know where sbf is now     \n",
       "3                december buys cvna  182k to  2 500 000    \n",
       "4       the dumbest reason in the world to buy a stoc...   \n",
       "...                                                  ...   \n",
       "40801                         next week on stock market    \n",
       "40802                          whatcha doin  here  huh     \n",
       "40803  commerzbank ag down 12   credit suisse group a...   \n",
       "40804  coca cola   ko  vs pepsi   pep   are either wo...   \n",
       "40805  meta  the hottest stock in tech  is up 140  si...   \n",
       "\n",
       "                                                 answers            tags  \\\n",
       "0      cut losses early  take profits always simple c...     stockmarket   \n",
       "1       we have exceeded all profit expectations  tha...     stockmarket   \n",
       "2      i ve worked with a few people that have gotten...  wallstreetbets   \n",
       "3         user report                            tota...  wallstreetbets   \n",
       "4      i don t think those quotes are that conflictin...     stockmarket   \n",
       "...                                                  ...             ...   \n",
       "40801    it seems to be mimicking my total account value  wallstreetbets   \n",
       "40802  this is funny  the guy with glass actually got...     stockmarket   \n",
       "40803  my portfolio is up 1 08  today  so far   also ...     stockmarket   \n",
       "40804                                         izbrisano        dividends   \n",
       "40805    i almost bought that shit at the low god dammit          stocks   \n",
       "\n",
       "                                         question_tokens  \\\n",
       "0      [[CLS], trade, ##r, who, made, money, with, ti...   \n",
       "1      [[CLS], leak, ##ed, email, from, microsoft, ce...   \n",
       "2      [[CLS], does, anyone, know, where, sb, ##f, is...   \n",
       "3      [[CLS], december, buys, cv, ##na, 182, ##k, to...   \n",
       "4      [[CLS], the, dum, ##bes, ##t, reason, in, the,...   \n",
       "...                                                  ...   \n",
       "40801      [[CLS], next, week, on, stock, market, [SEP]]   \n",
       "40802  [[CLS], what, ##cha, do, ##in, here, hu, ##h, ...   \n",
       "40803  [[CLS], commer, ##zb, ##ank, ag, down, 12, cre...   \n",
       "40804  [[CLS], coc, ##a, cola, ko, vs, pepsi, pep, ar...   \n",
       "40805  [[CLS], meta, the, hot, ##test, stock, in, tec...   \n",
       "\n",
       "                                           answer_tokens  \\\n",
       "0      [[CLS], cut, losses, early, take, profits, alw...   \n",
       "1      [[CLS], we, have, exceeded, all, profit, expec...   \n",
       "2      [[CLS], i, ve, worked, with, a, few, people, t...   \n",
       "3      [[CLS], user, report, total, submissions, 6, f...   \n",
       "4      [[CLS], i, don, t, think, those, quotes, are, ...   \n",
       "...                                                  ...   \n",
       "40801  [[CLS], it, seems, to, be, mimi, ##cki, ##ng, ...   \n",
       "40802  [[CLS], this, is, fun, ##ny, the, guy, with, g...   \n",
       "40803  [[CLS], my, portfolio, is, up, 1, 08, today, s...   \n",
       "40804              [[CLS], i, ##zb, ##ris, ##ano, [SEP]]   \n",
       "40805  [[CLS], i, almost, bought, that, shi, ##t, at,...   \n",
       "\n",
       "                                            question_ids  \\\n",
       "0      [3, 582, 437, 412, 295, 1247, 20, 4763, 4001, ...   \n",
       "1      [3, 12641, 268, 4679, 23, 3466, 2303, 8276, 19...   \n",
       "2       [3, 262, 7355, 695, 214, 7775, 1423, 17, 212, 4]   \n",
       "3      [3, 109, 7233, 7314, 2886, 17104, 994, 9, 513,...   \n",
       "4      [3, 6, 18997, 25137, 463, 2040, 10, 6, 907, 9,...   \n",
       "...                                                  ...   \n",
       "40801                      [3, 165, 1952, 19, 93, 52, 4]   \n",
       "40802    [3, 163, 9118, 123, 1419, 1094, 10374, 1078, 4]   \n",
       "40803  [3, 27903, 21596, 8515, 2708, 269, 315, 97, 11...   \n",
       "40804  [3, 16632, 363, 25424, 5338, 4364, 10987, 1327...   \n",
       "40805  [3, 12245, 6, 4387, 13850, 93, 10, 4579, 17, 1...   \n",
       "\n",
       "                                              answer_ids  \n",
       "0      [3, 2726, 274, 634, 362, 1458, 1433, 4665, 499...  \n",
       "1      [3, 13, 29, 2365, 69, 358, 746, 15, 304, 960, ...  \n",
       "2      [3, 44, 829, 4080, 20, 11, 806, 1043, 15, 29, ...  \n",
       "3      [3, 2502, 125, 87, 13777, 1146, 78, 921, 10, 7...  \n",
       "4      [3, 44, 4950, 599, 135, 151, 12244, 21, 15, 24...  \n",
       "...                                                  ...  \n",
       "40801  [3, 41, 1998, 9, 25, 27272, 26497, 1071, 657, ...  \n",
       "40802  [3, 26, 17, 15782, 5233, 6, 10037, 20, 4639, 8...  \n",
       "40803  [3, 657, 318, 17, 129, 428, 7694, 1163, 96, 12...  \n",
       "40804                     [3, 44, 21596, 6632, 10225, 4]  \n",
       "40805  [3, 44, 1628, 4774, 15, 11125, 463, 28, 6, 536...  \n",
       "\n",
       "[40806 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_df_reddit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
