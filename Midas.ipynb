{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (4.32.1)\n",
      "Requirement already satisfied: filelock in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/apasalic/anaconda/envs/nlp_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-27 20:54:06.096251: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-27 20:54:07.602372: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#FinanceInc/finbert-pretrain\n",
    "finbert_tokenizer = AutoTokenizer.from_pretrained(\"FinanceInc/finbert-pretrain\", from_pt=True)\n",
    "finbert_model = TFAutoModel.from_pretrained(\"FinanceInc/finbert-pretrain\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  109751808 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,751,808\n",
      "Trainable params: 109,751,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "finbert_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag': 'welcome', 'patterns': ['Hi', 'Hello', 'How are you', 'whats up', 'How do you do', 'How’s the day?', 'Hey are you there', 'How is everything going', 'glad to meet you'], 'responses': ['Hello', 'Glad to see you again', 'Hi there, How can I help  you', 'Hello! what you are looking for?', 'Hello, how may I help you']}\n",
      "{'tag': 'endingnote', 'patterns': ['see you. bye', 'Good Bye', 'ok then bye', 'That’ s enough for me', ' Im leaving', 'See u later! Goodbye', 'nice to meet you', 'The bargaining session was fun!I’m happy that I got it at cheap price, see u again', 'Enjoyed the experience, good bye'], 'responses': ['Hey, Thank you for visiting', 'Hope to see you again, it was nice talking with you', ' wish you a good day! Hope to have a talk with you later', 'Thanks for your time with us.Hope you enjoyed it and satisfied. See you later', 'Sad to see you go. Come whenever you need to bye from us. Stay intouch.']}\n",
      "{'tag': 'name', 'patterns': ['whats you name?', 'who are you?', 'what can I call you', 'tell me your name', 'Are u a robot', 'Are you a chatbot'], 'responses': ['It’s FinBot here, a digital+financial assistant to help you out', 'You can call me FinBot.Im a chatRobot/chatbot, tell me what you want', 'I’m FinBot,a digital+financial assistant, I can guide you in our ecommerce website.', 'Its FinBot Here,a digital +financial assistant. How may I help you?']}\n",
      "{'tag': 'shopping', 'patterns': ['I would like to buy something here', 'can I buy something', 'What all things are there', 'can you recommend me something from here', 'is there any thing cheaper here', 'Hey, I want a black shoe'], 'responses': ['Yes please, we have a lot of new collections for you', 'Ofcourse, there are new offers for you, fantastic selections, choose what interests you!', 'Well casual shoes at Rs 220, this offer won’t stay much', 'there are good varieties of coloured shoes too also there are black formal shoes. Take one']}\n",
      "{'tag': 'time period', 'patterns': ['till what time this be offered?', 'When will the shop close?', 'when will the shop open', 'How much time it will take for delivery', 'When will this site close?', 'When are you people open', 'When will this store be open?', 'Is this store will be open at Sunday?'], 'responses': ['Our shop centre will be open from 9 am-9pm in all the days', 'Yes, we are operating on all the weekdays from 9 am to 9pm', 'We are there to provide services from Monday-sunday from 9 am-9pm', 'We are operating from 9 am-9 pm every day']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('./data/gopikasr/DataChatBot.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for i in data['intents'][:5]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QnA_dict(data):\n",
    "    QnA = {'questions':[], 'answers':[], 'tags':[]}\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            for response in intent['responses']:\n",
    "                QnA['questions'].append(pattern)\n",
    "                QnA['answers'].append(response)\n",
    "                QnA['tags'].append(intent['tag'])\n",
    "    return QnA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "705\n"
     ]
    }
   ],
   "source": [
    "qna = QnA_dict(data)\n",
    "\n",
    "print(len(qna['questions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "qna_df=pd.DataFrame(qna)\n",
    "qna_df.to_csv('qna_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello</td>\n",
       "      <td>welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Glad to see you again</td>\n",
       "      <td>welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi there, How can I help  you</td>\n",
       "      <td>welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello! what you are looking for?</td>\n",
       "      <td>welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello, how may I help you</td>\n",
       "      <td>welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Thank you</td>\n",
       "      <td>You are welcome</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Thank you</td>\n",
       "      <td>No problem. Its my pleasure to help you</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Thank you so much for your help</td>\n",
       "      <td>Its my pleasure.</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Thank you so much for your help</td>\n",
       "      <td>You are welcome</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Thank you so much for your help</td>\n",
       "      <td>No problem. Its my pleasure to help you</td>\n",
       "      <td>Thank you</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           questions                                  answers  \\\n",
       "0                                 Hi                                    Hello   \n",
       "1                                 Hi                    Glad to see you again   \n",
       "2                                 Hi            Hi there, How can I help  you   \n",
       "3                                 Hi         Hello! what you are looking for?   \n",
       "4                                 Hi                Hello, how may I help you   \n",
       "..                               ...                                      ...   \n",
       "700                        Thank you                          You are welcome   \n",
       "701                        Thank you  No problem. Its my pleasure to help you   \n",
       "702  Thank you so much for your help                         Its my pleasure.   \n",
       "703  Thank you so much for your help                          You are welcome   \n",
       "704  Thank you so much for your help  No problem. Its my pleasure to help you   \n",
       "\n",
       "          tags  \n",
       "0      welcome  \n",
       "1      welcome  \n",
       "2      welcome  \n",
       "3      welcome  \n",
       "4      welcome  \n",
       "..         ...  \n",
       "700  Thank you  \n",
       "701  Thank you  \n",
       "702  Thank you  \n",
       "703  Thank you  \n",
       "704  Thank you  \n",
       "\n",
       "[705 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qna_df_reddit = pd.read_csv('qna_df_reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user report                            total submissions   10   first seen in wsb   2 years ago   total comments   332   previous best dd      account age   3 years   scan  comment     submission   \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define the stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenization\n",
    "    # tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words and lemmatize the words\n",
    "    # tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stop_words]\n",
    "    return text\n",
    "\n",
    "input_text = '\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**Total Submissions**|10|**First Seen In WSB**|2 years ago\\n**Total Comments**|332|**Previous Best DD**|\\n**Account Age**|3 years|[^scan ^comment ](https://www.reddit.com/message/compose/?to=VisualMod&subject=scan_comment&message=Replace%20this%20text%20with%20a%20comment%20ID%20(which%20looks%20like%20h26cq3k\\\\)%20to%20have%20the%20bot%20scan%20your%20comment%20and%20correct%20your%20first%20seen%20date.)|[^scan ^submission ](https://www.reddit.com/message/compose/?to=VisualMod&subject=scan_submission&message=Replace%20this%20text%20with%20a%20submission%20ID%20(which%20looks%20like%20h26cq3k\\\\)%20to%20have%20the%20bot%20scan%20your%20submission%20and%20correct%20your%20first%20seen%20date.)'\n",
    "preprocessed_text = preprocess_text(input_text)\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qna_df['question_tokens'] = qna_df['questions'].apply(lambda x: finbert_tokenizer.tokenize(x))\n",
    "qna_df['answer_tokens'] = qna_df['answers'].apply(lambda x: finbert_tokenizer.tokenize(x))\n",
    "\n",
    "qna_df['question_tokens'] = qna_df['question_tokens'].apply(lambda x: ['[CLS]'] + x + ['[SEP]'])\n",
    "qna_df['answer_tokens'] = qna_df['answer_tokens'].apply(lambda x: ['[CLS]'] + x + ['[SEP]'])\n",
    "\n",
    "qna_df['question_ids'] = qna_df['question_tokens'].apply(lambda x: finbert_tokenizer.convert_tokens_to_ids(x))\n",
    "qna_df['answer_ids'] = qna_df['answer_tokens'].apply(lambda x: finbert_tokenizer.convert_tokens_to_ids(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "      <th>tags</th>\n",
       "      <th>question_tokens</th>\n",
       "      <th>answer_tokens</th>\n",
       "      <th>question_ids</th>\n",
       "      <th>answer_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello</td>\n",
       "      <td>welcome</td>\n",
       "      <td>[[CLS], hi, [SEP]]</td>\n",
       "      <td>[[CLS], hello, [SEP]]</td>\n",
       "      <td>[3, 4325, 4]</td>\n",
       "      <td>[3, 23738, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Glad to see you again</td>\n",
       "      <td>welcome</td>\n",
       "      <td>[[CLS], hi, [SEP]]</td>\n",
       "      <td>[[CLS], glad, to, see, you, again, [SEP]]</td>\n",
       "      <td>[3, 4325, 4]</td>\n",
       "      <td>[3, 10079, 9, 153, 40, 1117, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hi there, How can I help  you</td>\n",
       "      <td>welcome</td>\n",
       "      <td>[[CLS], hi, [SEP]]</td>\n",
       "      <td>[[CLS], hi, there, ,, how, can, i, help, you, ...</td>\n",
       "      <td>[3, 4325, 4]</td>\n",
       "      <td>[3, 4325, 112, 585, 283, 110, 44, 904, 40, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello! what you are looking for?</td>\n",
       "      <td>welcome</td>\n",
       "      <td>[[CLS], hi, [SEP]]</td>\n",
       "      <td>[[CLS], hello, !, what, you, are, looking, for...</td>\n",
       "      <td>[3, 4325, 4]</td>\n",
       "      <td>[3, 23738, 17293, 163, 40, 21, 601, 14, 4642, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Hello, how may I help you</td>\n",
       "      <td>welcome</td>\n",
       "      <td>[[CLS], hi, [SEP]]</td>\n",
       "      <td>[[CLS], hello, ,, how, may, i, help, you, [SEP]]</td>\n",
       "      <td>[3, 4325, 4]</td>\n",
       "      <td>[3, 23738, 585, 283, 32, 44, 904, 40, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>Thank you</td>\n",
       "      <td>You are welcome</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>[[CLS], thank, you, [SEP]]</td>\n",
       "      <td>[[CLS], you, are, welcome, [SEP]]</td>\n",
       "      <td>[3, 332, 40, 4]</td>\n",
       "      <td>[3, 40, 21, 2133, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>Thank you</td>\n",
       "      <td>No problem. Its my pleasure to help you</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>[[CLS], thank, you, [SEP]]</td>\n",
       "      <td>[[CLS], no, problem, ., its, my, pleasure, to,...</td>\n",
       "      <td>[3, 332, 40, 4]</td>\n",
       "      <td>[3, 141, 3221, 48, 38, 657, 11109, 9, 904, 40, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>Thank you so much for your help</td>\n",
       "      <td>Its my pleasure.</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>[[CLS], thank, you, so, much, for, your, help,...</td>\n",
       "      <td>[[CLS], its, my, pleasure, ., [SEP]]</td>\n",
       "      <td>[3, 332, 40, 96, 406, 14, 185, 904, 4]</td>\n",
       "      <td>[3, 38, 657, 11109, 48, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>Thank you so much for your help</td>\n",
       "      <td>You are welcome</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>[[CLS], thank, you, so, much, for, your, help,...</td>\n",
       "      <td>[[CLS], you, are, welcome, [SEP]]</td>\n",
       "      <td>[3, 332, 40, 96, 406, 14, 185, 904, 4]</td>\n",
       "      <td>[3, 40, 21, 2133, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>Thank you so much for your help</td>\n",
       "      <td>No problem. Its my pleasure to help you</td>\n",
       "      <td>Thank you</td>\n",
       "      <td>[[CLS], thank, you, so, much, for, your, help,...</td>\n",
       "      <td>[[CLS], no, problem, ., its, my, pleasure, to,...</td>\n",
       "      <td>[3, 332, 40, 96, 406, 14, 185, 904, 4]</td>\n",
       "      <td>[3, 141, 3221, 48, 38, 657, 11109, 9, 904, 40, 4]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>705 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           questions                                  answers  \\\n",
       "0                                 Hi                                    Hello   \n",
       "1                                 Hi                    Glad to see you again   \n",
       "2                                 Hi            Hi there, How can I help  you   \n",
       "3                                 Hi         Hello! what you are looking for?   \n",
       "4                                 Hi                Hello, how may I help you   \n",
       "..                               ...                                      ...   \n",
       "700                        Thank you                          You are welcome   \n",
       "701                        Thank you  No problem. Its my pleasure to help you   \n",
       "702  Thank you so much for your help                         Its my pleasure.   \n",
       "703  Thank you so much for your help                          You are welcome   \n",
       "704  Thank you so much for your help  No problem. Its my pleasure to help you   \n",
       "\n",
       "          tags                                    question_tokens  \\\n",
       "0      welcome                                 [[CLS], hi, [SEP]]   \n",
       "1      welcome                                 [[CLS], hi, [SEP]]   \n",
       "2      welcome                                 [[CLS], hi, [SEP]]   \n",
       "3      welcome                                 [[CLS], hi, [SEP]]   \n",
       "4      welcome                                 [[CLS], hi, [SEP]]   \n",
       "..         ...                                                ...   \n",
       "700  Thank you                         [[CLS], thank, you, [SEP]]   \n",
       "701  Thank you                         [[CLS], thank, you, [SEP]]   \n",
       "702  Thank you  [[CLS], thank, you, so, much, for, your, help,...   \n",
       "703  Thank you  [[CLS], thank, you, so, much, for, your, help,...   \n",
       "704  Thank you  [[CLS], thank, you, so, much, for, your, help,...   \n",
       "\n",
       "                                         answer_tokens  \\\n",
       "0                                [[CLS], hello, [SEP]]   \n",
       "1            [[CLS], glad, to, see, you, again, [SEP]]   \n",
       "2    [[CLS], hi, there, ,, how, can, i, help, you, ...   \n",
       "3    [[CLS], hello, !, what, you, are, looking, for...   \n",
       "4     [[CLS], hello, ,, how, may, i, help, you, [SEP]]   \n",
       "..                                                 ...   \n",
       "700                  [[CLS], you, are, welcome, [SEP]]   \n",
       "701  [[CLS], no, problem, ., its, my, pleasure, to,...   \n",
       "702               [[CLS], its, my, pleasure, ., [SEP]]   \n",
       "703                  [[CLS], you, are, welcome, [SEP]]   \n",
       "704  [[CLS], no, problem, ., its, my, pleasure, to,...   \n",
       "\n",
       "                               question_ids  \\\n",
       "0                              [3, 4325, 4]   \n",
       "1                              [3, 4325, 4]   \n",
       "2                              [3, 4325, 4]   \n",
       "3                              [3, 4325, 4]   \n",
       "4                              [3, 4325, 4]   \n",
       "..                                      ...   \n",
       "700                         [3, 332, 40, 4]   \n",
       "701                         [3, 332, 40, 4]   \n",
       "702  [3, 332, 40, 96, 406, 14, 185, 904, 4]   \n",
       "703  [3, 332, 40, 96, 406, 14, 185, 904, 4]   \n",
       "704  [3, 332, 40, 96, 406, 14, 185, 904, 4]   \n",
       "\n",
       "                                            answer_ids  \n",
       "0                                        [3, 23738, 4]  \n",
       "1                      [3, 10079, 9, 153, 40, 1117, 4]  \n",
       "2        [3, 4325, 112, 585, 283, 110, 44, 904, 40, 4]  \n",
       "3     [3, 23738, 17293, 163, 40, 21, 601, 14, 4642, 4]  \n",
       "4             [3, 23738, 585, 283, 32, 44, 904, 40, 4]  \n",
       "..                                                 ...  \n",
       "700                               [3, 40, 21, 2133, 4]  \n",
       "701  [3, 141, 3221, 48, 38, 657, 11109, 9, 904, 40, 4]  \n",
       "702                         [3, 38, 657, 11109, 48, 4]  \n",
       "703                               [3, 40, 21, 2133, 4]  \n",
       "704  [3, 141, 3221, 48, 38, 657, 11109, 9, 904, 40, 4]  \n",
       "\n",
       "[705 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
